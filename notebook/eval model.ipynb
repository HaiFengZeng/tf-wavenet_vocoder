{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import librosa\n",
    "import math\n",
    "from time import time\n",
    "sys.path.append('..')\n",
    "from wavenet.model import WaveNetModel\n",
    "from wavenet.ops import mu_law_encode, mu_law_decode\n",
    "from IPython.display import Audio\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "batch_size = 1\n",
    "filter_width = 3\n",
    "n_stack = 2\n",
    "max_dilation = 10\n",
    "dilations = [2 ** i for j in range(n_stack) for i in range(max_dilation)]\n",
    "\n",
    "residual_channels, dilation_channels, skip_channels = 128, 128, 256\n",
    "use_biases = True\n",
    "quantization_channels = 256\n",
    "gc_cardinality = None\n",
    "gc_channels = None\n",
    "scalar_input = False\n",
    "initial_filter_width = filter_width\n",
    "\n",
    "net = WaveNetModel(batch_size=batch_size,\n",
    "                        dilations=dilations,\n",
    "                        filter_width=filter_width,\n",
    "                        scalar_input=scalar_input,\n",
    "                        initial_filter_width=initial_filter_width,\n",
    "                        residual_channels=residual_channels,\n",
    "                        dilation_channels=dilation_channels,\n",
    "                        quantization_channels=quantization_channels,\n",
    "                        skip_channels=skip_channels,\n",
    "                        global_condition_channels=gc_channels,\n",
    "                        global_condition_cardinality=gc_cardinality,\n",
    "                        use_biases=use_biases,\n",
    "                        local_condition_channels=1)\n",
    "\n",
    "gen_num = tf.placeholder(tf.int32)\n",
    "input_batch = tf.placeholder(tf.float32)\n",
    "lc_batch = tf.placeholder(tf.float32)\n",
    "ml_encoded = mu_law_encode(input_batch, quantization_channels)\n",
    "encoded = net._one_hot(ml_encoded)\n",
    "\n",
    "raw_output = net.create_network(encoded, lc_batch, None)\n",
    "out = tf.reshape(raw_output, [-1, quantization_channels])\n",
    "proba = tf.cast(tf.nn.softmax(tf.cast(out, tf.float64)), tf.float32)\n",
    "# loss = net.loss(input_placeholder, None, None)\n",
    "# optimizer = tf.train.AdamOptimizer(0.001)\n",
    "# optim = optimizer.minimize(loss, var_list=tf.trainable_variables())\n",
    "\n",
    "# For generation\n",
    "generation_batch_size = 1\n",
    "sample_placeholder = tf.placeholder(tf.int32)\n",
    "lc_placeholder = tf.placeholder(tf.float32)\n",
    "gen_num = tf.placeholder(tf.int32)\n",
    "\n",
    "next_sample_prob, layers_out, qs = \\\n",
    "    net.predict_proba_incremental(sample_placeholder, gen_num, batch_size=generation_batch_size,\n",
    "                                 local_condition=lc_placeholder)\n",
    "\n",
    "initial = tf.placeholder(tf.float32)\n",
    "others = tf.placeholder(tf.float32)\n",
    "update_q_ops = net.create_update_q_ops(qs, initial, others, gen_num, batch_size=generation_batch_size)\n",
    "\n",
    "var_q = net.get_vars_q()\n",
    "\n",
    "print(\"created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "src, _ = librosa.load(\"voice.wav\", sr=16000)\n",
    "src = src[:len(src)//4]\n",
    "n_samples = len(src)\n",
    "src = src.reshape(-1, 1)\n",
    "src = np.pad(src, [[net.receptive_field, 0], [0, 0]],'constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed: 32.192336082458496\n",
      "result: [255 255 255 ...  19   1  57]\n",
      "generated samples: [[255 255 255 ...  19   1  57]]\n",
      "difference between result and samples: 0\n"
     ]
    }
   ],
   "source": [
    "sess_config = tf.ConfigProto(\n",
    "    device_count = {'GPU': 0}\n",
    ")\n",
    "with tf.Session(config=sess_config) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    _lc = src.reshape(1, -1, 1)\n",
    "    result, _encoded = sess.run([proba, ml_encoded], \n",
    "                                   feed_dict={input_batch:src, lc_batch:_lc})\n",
    "    _encoded = _encoded.reshape(batch_size, -1)\n",
    "    result = np.argmax(result, axis=-1)\n",
    "\n",
    "    sess.run(tf.variables_initializer(var_q))\n",
    "    \n",
    "    t = time()\n",
    "    samples= []\n",
    "    for j in range(net.receptive_field-1):\n",
    "        feed_dict = {sample_placeholder:_encoded[:,j], lc_placeholder:[[0]], gen_num:j}\n",
    "        prob, _layers = sess.run([next_sample_prob, layers_out], feed_dict=feed_dict)\n",
    "        sess.run(update_q_ops, feed_dict={initial:_layers[0], others:np.array(_layers[1:]), gen_num:j})\n",
    "\n",
    "    for j in range(net.receptive_field-1, _encoded.shape[-1]):\n",
    "        feed_dict = {sample_placeholder:_encoded[:,j], \n",
    "                     lc_placeholder:_lc[:,j],\n",
    "                     gen_num:j}\n",
    "        prob, _layers = sess.run([next_sample_prob, layers_out], feed_dict=feed_dict)\n",
    "        sess.run(update_q_ops, feed_dict={initial:_layers[0], others:np.array(_layers[1:]), gen_num:j})\n",
    "        sample = np.argmax(prob, axis=-1)\n",
    "        samples.append(sample)\n",
    "        \n",
    "    samples = np.array(samples).T\n",
    "    print(\"elapsed:\", time()-t)\n",
    "\n",
    "print(\"result:\", result)\n",
    "print(\"generated samples:\", samples)\n",
    "print(\"difference between result and samples:\", np.abs(result-samples).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
